{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 903400\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(100, (3, 3), strides=(2, 2), padding='same', input_shape=(720, 1280, 3)))\n",
    "model.add(Conv2D(200, (3, 3), strides=(2, 2), padding='same'))\n",
    "model.add(Conv2D(400, (3, 3), strides=(2, 2), padding='same'))\n",
    "\n",
    "# Print the number of parameters in the CNN\n",
    "print(\"Total number of parameters:\", model.count_params())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Minimum total RAM needed: 37712800 bytes\n"
     ]
    }
   ],
   "source": [
    "# Create a random input image\n",
    "input_image = np.random.rand(1, 720, 1280, 3).astype(np.float32)\n",
    "\n",
    "# Make a prediction with the CNN and measure the memory usage\n",
    "model.predict(input_image)\n",
    "memory_usage = model.output_shape[1] * model.output_shape[2] * model.output_shape[3] * 4 + \\\n",
    "               model.input_shape[1] * model.input_shape[2] * model.input_shape[3] * 4 + \\\n",
    "               model.count_params() * 4\n",
    "print(\"Minimum total RAM needed:\", memory_usage, \"bytes\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Minimum total RAM needed with 8-bit floats: 9428200 bytes\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with the CNN and measure the memory usage with 8-bit floats\n",
    "model.predict(input_image.astype(np.float32) / 256)\n",
    "memory_usage = model.output_shape[1] * model.output_shape[2] * model.output_shape[3] + \\\n",
    "               model.input_shape[1] * model.input_shape[2] * model.input_shape[3] + \\\n",
    "               model.count_params()\n",
    "print(\"Minimum total RAM needed with 8-bit floats:\", memory_usage, \"bytes\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 52s 52s/step\n",
      "Minimum total RAM needed with 20 input images: 685597600 bytes\n"
     ]
    }
   ],
   "source": [
    "# Create 20 random input images\n",
    "input_images = np.random.rand(20, 720, 1280, 3).astype(np.float32)\n",
    "\n",
    "# Make a prediction with the CNN and measure the memory usage with 20 input images\n",
    "model.predict(input_images)\n",
    "memory_usage = 20 * (model.output_shape[1] * model.output_shape[2] * model.output_shape[3] * 4 + \\\n",
    "                     model.input_shape[1] * model.input_shape[2] * model.input_shape[3] * 4) + \\\n",
    "               model.count_params() * 4\n",
    "print(\"Minimum total RAM needed with 20 input images:\", memory_usage, \"bytes\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape input data to be 4D (batch_size, height, width, channels)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Define image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(64, kernel_size=3, activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 375s 395ms/step - loss: 0.7070 - accuracy: 0.7466 - val_loss: 0.4152 - val_accuracy: 0.8467 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 367s 391ms/step - loss: 0.5001 - accuracy: 0.8178 - val_loss: 0.4173 - val_accuracy: 0.8504 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 333s 355ms/step - loss: 0.4500 - accuracy: 0.8356 - val_loss: 0.3501 - val_accuracy: 0.8737 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 342s 365ms/step - loss: 0.4204 - accuracy: 0.8458 - val_loss: 0.2924 - val_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 335s 357ms/step - loss: 0.4058 - accuracy: 0.8498 - val_loss: 0.3870 - val_accuracy: 0.8612 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 337s 359ms/step - loss: 0.3885 - accuracy: 0.8571 - val_loss: 0.3117 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "139/938 [===>..........................] - ETA: 6:40 - loss: 0.3938 - accuracy: 0.8540"
     ]
    }
   ],
   "source": [
    "# Define the learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model with batch size of 64 for 20 epochs using the image generator\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=64), epochs=20, validation_data=(x_test, y_test), callbacks=[keras.callbacks.LearningRateScheduler(scheduler)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}